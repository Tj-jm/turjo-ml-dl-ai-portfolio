# -*- coding: utf-8 -*-
"""bangla-ocr.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mkj1x8lILMqO62ZcN8pXQk4l-eYmBzqJ
"""

!pip install tensorflow opencv-python


from google.colab import files
uploaded = files.upload()
# Upload:
#  - bangla_ocr_model.h5
#  - test_char.png (any single handwritten Bangla char image)

from keras.models import load_model
model = load_model("bangla_ocr_model.h5")
print("‚úÖ Model loaded.")

# üîç Load and predict image
import cv2
import numpy as np
from keras.preprocessing.image import img_to_array
import matplotlib.pyplot as plt

# üî° Put your original training label map here
class_names = ['‡¶Ö', '‡¶Ü', '‡¶á', '‡¶à', '‡¶â', '‡¶ä', '‡¶ã', '‡¶è', '‡¶ê', '‡¶ì', '‡¶î',
               '‡¶ï', '‡¶ñ', '‡¶ó', '‡¶ò', '‡¶ô', '‡¶ö', '‡¶õ', '‡¶ú', '‡¶ù', '‡¶û',
               '‡¶ü', '‡¶†', '‡¶°', '‡¶¢', '‡¶£', '‡¶§', '‡¶•', '‡¶¶', '‡¶ß', '‡¶®',
               '‡¶™', '‡¶´', '‡¶¨', '‡¶≠', '‡¶Æ', '‡¶Ø', '‡¶∞', '‡¶≤', '‡¶∂', '‡¶∑',
               '‡¶∏', '‡¶π', '‡¶°‡¶º', '‡¶¢‡¶º', '‡¶Ø‡¶º', '‡ßé', '‡ß¶', '‡ßß', '‡ß®', '‡ß©',
               '‡ß™', '‡ß´', '‡ß¨', '‡ß≠', '‡ßÆ', '‡ßØ']

# Change to your image filename
img_path = "ko.jpeg"

img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, (64, 64))
img = img_to_array(img).reshape(1, 64, 64, 1) / 255.0
pred = model.predict(img)[0]
predicted_label = class_names[np.argmax(pred)]

print(" Predicted character:", predicted_label)

# üñº Show the image
plt.imshow(cv2.imread(img_path), cmap='gray')
plt.title(f"Prediction: {predicted_label}")
plt.axis('off')
plt.show()

# Upload image from local machine
from google.colab import files
uploaded = files.upload()

# Get the uploaded filename
img_path = list(uploaded.keys())[0]

# Load and predict image
import cv2
import numpy as np
from keras.preprocessing.image import img_to_array
import matplotlib.pyplot as plt

# Class label map (update if yours is different)
class_names = ['‡¶Ö', '‡¶Ü', '‡¶á', '‡¶à', '‡¶â', '‡¶ä', '‡¶ã', '‡¶è', '‡¶ê', '‡¶ì', '‡¶î',
               '‡¶ï', '‡¶ñ', '‡¶ó', '‡¶ò', '‡¶ô', '‡¶ö', '‡¶õ', '‡¶ú', '‡¶ù', '‡¶û',
               '‡¶ü', '‡¶†', '‡¶°', '‡¶¢', '‡¶£', '‡¶§', '‡¶•', '‡¶¶', '‡¶ß', '‡¶®',
               '‡¶™', '‡¶´', '‡¶¨', '‡¶≠', '‡¶Æ', '‡¶Ø', '‡¶∞', '‡¶≤', '‡¶∂', '‡¶∑',
               '‡¶∏', '‡¶π', '‡¶°‡¶º', '‡¶¢‡¶º', '‡¶Ø‡¶º', '‡ßé', '‡ß¶', '‡ßß', '‡ß®', '‡ß©',
               '‡ß™', '‡ß´', '‡ß¨', '‡ß≠', '‡ßÆ', '‡ßØ']

img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
img = cv2.resize(img, (64, 64))
img = img_to_array(img).reshape(1, 64, 64, 1) / 255.0

pred = model.predict(img)[0]
print(np.argmax(pred))
predicted_label = class_names[np.argmax(pred)]

print("Predicted character:", predicted_label)

plt.imshow(cv2.imread(img_path), cmap='gray')
plt.title(f"Prediction: {predicted_label}")
plt.axis('off')
plt.show()

import cv2
import numpy as np
from keras.preprocessing.image import img_to_array

def preprocess_stylized_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)

    # Threshold + invert
    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Crop bounding box
    coords = cv2.findNonZero(thresh)
    x, y, w, h = cv2.boundingRect(coords)
    cropped = thresh[y:y+h, x:x+w]

    # Resize while keeping aspect ratio and padding
    size = 64
    h, w = cropped.shape
    scale = size / max(h, w)
    resized = cv2.resize(cropped, (int(w * scale), int(h * scale)))

    # Create square canvas and center
    square = np.ones((size, size), dtype=np.uint8) * 0  # black background
    x_offset = (size - resized.shape[1]) // 2
    y_offset = (size - resized.shape[0]) // 2
    square[y_offset:y_offset+resized.shape[0], x_offset:x_offset+resized.shape[1]] = resized

    # Normalize and reshape
    img_array = img_to_array(square).reshape(1, 64, 64, 1) / 255.0
    return img_array

img = preprocess_stylized_image("ko.jpeg")
pred = model.predict(img)[0]
print("Predicted character:", class_names[np.argmax(pred)])

import cv2
import numpy as np
from keras.preprocessing.image import img_to_array
from tensorflow.keras.models import load_model
import matplotlib.pyplot as plt
from google.colab import files  # remove this line if using Jupyter



# Class names
class_names = ['‡¶Ö', '‡¶Ü', '‡¶á', '‡¶à', '‡¶â', '‡¶ä', '‡¶ã', '‡¶è', '‡¶ê', '‡¶ì', '‡¶î',
               '‡¶ï', '‡¶ñ', '‡¶ó', '‡¶ò', '‡¶ô', '‡¶ö', '‡¶õ', '‡¶ú', '‡¶ù', '‡¶û',
               '‡¶ü', '‡¶†', '‡¶°', '‡¶¢', '‡¶£', '‡¶§', '‡¶•', '‡¶¶', '‡¶ß', '‡¶®',
               '‡¶™', '‡¶´', '‡¶¨', '‡¶≠', '‡¶Æ', '‡¶Ø', '‡¶∞', '‡¶≤', '‡¶∂', '‡¶∑',
               '‡¶∏', '‡¶π', '‡¶°‡¶º', '‡¶¢‡¶º', '‡¶Ø‡¶º', '‡ßé', '‡ß¶', '‡ßß', '‡ß®', '‡ß©',
               '‡ß™', '‡ß´', '‡ß¨', '‡ß≠', '‡ßÆ', '‡ßØ']

# Preprocessing function
def preprocess_stylized_image(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    coords = cv2.findNonZero(thresh)
    x, y, w, h = cv2.boundingRect(coords)
    cropped = thresh[y:y+h, x:x+w]
    size = 64
    h, w = cropped.shape
    scale = size / max(h, w)
    resized = cv2.resize(cropped, (int(w * scale), int(h * scale)))
    square = np.ones((size, size), dtype=np.uint8) * 0
    x_offset = (size - resized.shape[1]) // 2
    y_offset = (size - resized.shape[0]) // 2
    square[y_offset:y_offset+resized.shape[0], x_offset:x_offset+resized.shape[1]] = resized
    img_array = img_to_array(square).reshape(1, 64, 64, 1) / 255.0
    return img_array, square

# Upload and predict
uploaded = files.upload()
img_path = next(iter(uploaded))

img_array, display_img = preprocess_stylized_image(img_path)
pred = model.predict(img_array)[0]
predicted_label = class_names[np.argmax(pred)]

print("Predicted character:", predicted_label)

plt.imshow(display_img, cmap='gray')
plt.title(f"Prediction: {predicted_label}")
plt.axis('off')
plt.show()

# STEP 1: Install dependencies
!pip install tensorflow opencv-python-headless --quiet

# STEP 2: Upload model + line image
from google.colab import files
uploaded = files.upload()  # Upload both model.h5 and line image

# Identify uploaded model and image file

img_file = [f for f in uploaded if not f.endswith('.h5')][0]

# STEP 3: Load model
from tensorflow.keras.models import load_model


# STEP 4: Character label list (60 total)
class_names = ['‡¶Ö', '‡¶Ü', '‡¶á', '‡¶à', '‡¶â', '‡¶ä', '‡¶ã', '‡¶è', '‡¶ê', '‡¶ì', '‡¶î',
               '‡¶ï', '‡¶ñ', '‡¶ó', '‡¶ò', '‡¶ô', '‡¶ö', '‡¶õ', '‡¶ú', '‡¶ù', '‡¶û',
               '‡¶ü', '‡¶†', '‡¶°', '‡¶¢', '‡¶£', '‡¶§', '‡¶•', '‡¶¶', '‡¶ß', '‡¶®',
               '‡¶™', '‡¶´', '‡¶¨', '‡¶≠', '‡¶Æ', '‡¶Ø', '‡¶∞', '‡¶≤', '‡¶∂', '‡¶∑',
               '‡¶∏', '‡¶π', '‡¶°‡¶º', '‡¶¢‡¶º', '‡¶Ø‡¶º', '‡ßé', '‡ß¶', '‡ßß', '‡ß®', '‡ß©',
               '‡ß™', '‡ß´', '‡ß¨', '‡ß≠', '‡ßÆ', '‡ßØ']

# Auto-adjust class_names to model output
import numpy as np
from keras.preprocessing.image import img_to_array
import cv2
import matplotlib.pyplot as plt

model_output_classes = model.output_shape[-1]
if len(class_names) != model_output_classes:
    class_names = class_names[:model_output_classes]

# STEP 5: Predict function
def predict_line(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"Error: Could not load image from {img_path}")
        return

    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    bounding_boxes = [cv2.boundingRect(c) for c in contours]
    if not bounding_boxes:
        print("No characters detected.")
        plt.imshow(cv2.imread(img_path), cmap='gray')
        plt.title("No characters detected")
        plt.axis('off')
        plt.show()
        return

    bounding_boxes = sorted(bounding_boxes, key=lambda x: x[0])  # Left to right

    predicted_text = ""
    for box in bounding_boxes:
        x, y, w, h = box
        roi = thresh[y:y+h, x:x+w]
        size = 64
        h, w = roi.shape
        scale = size / max(h, w)
        resized = cv2.resize(roi, (int(w * scale), int(h * scale)))
        square = np.zeros((size, size), dtype=np.uint8)
        x_offset = (size - resized.shape[1]) // 2
        y_offset = (size - resized.shape[0]) // 2
        square[y_offset:y_offset+resized.shape[0], x_offset:x_offset+resized.shape[1]] = resized
        img_array = img_to_array(square).reshape(1, 64, 64, 1) / 255.0

        pred = model.predict(img_array, verbose=0)[0]
        label = class_names[np.argmax(pred)]
        predicted_text += label

    print("Predicted Line:", predicted_text)
    plt.imshow(cv2.imread(img_path), cmap='gray')
    plt.axis('off')
    plt.title(f"Predicted: {predicted_text}")
    plt.show()

# Run it
predict_line(img_file)

# STEP 1: Install dependencies
!pip install tensorflow opencv-python-headless --quiet

# STEP 2: Upload only the line image
from google.colab import files
uploaded = files.upload()  # Just upload image (not model)

img_file = list(uploaded.keys())[0]  # Grab the image filename

# STEP 3: Load pre-existing model (already in Colab runtime)
from tensorflow.keras.models import load_model
model = load_model('bangla_ocr_model.h5')  # Use exact filename if different

# STEP 4: Character label list (adjust if your model has fewer outputs)
class_names = ['‡¶Ö', '‡¶Ü', '‡¶á', '‡¶à', '‡¶â', '‡¶ä', '‡¶ã', '‡¶è', '‡¶ê', '‡¶ì', '‡¶î',
               '‡¶ï', '‡¶ñ', '‡¶ó', '‡¶ò', '‡¶ô', '‡¶ö', '‡¶õ', '‡¶ú', '‡¶ù', '‡¶û',
               '‡¶ü', '‡¶†', '‡¶°', '‡¶¢', '‡¶£', '‡¶§', '‡¶•', '‡¶¶', '‡¶ß', '‡¶®',
               '‡¶™', '‡¶´', '‡¶¨', '‡¶≠', '‡¶Æ', '‡¶Ø', '‡¶∞', '‡¶≤', '‡¶∂', '‡¶∑',
               '‡¶∏', '‡¶π', '‡¶°‡¶º', '‡¶¢‡¶º', '‡¶Ø‡¶º', '‡ßé', '‡ß¶', '‡ßß', '‡ß®', '‡ß©',
               '‡ß™', '‡ß´', '‡ß¨', '‡ß≠', '‡ßÆ', '‡ßØ']

# Auto-adjust to model output size
import numpy as np
from keras.preprocessing.image import img_to_array
import cv2
import matplotlib.pyplot as plt

output_dim = model.output_shape[-1]
if len(class_names) != output_dim:
    class_names = class_names[:output_dim]

# STEP 5: Prediction function
def predict_line(img_path):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    if img is None:
        print(f"Error loading image: {img_path}")
        return

    _, thresh = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    boxes = sorted([cv2.boundingRect(c) for c in contours], key=lambda b: b[0])

    predicted_text = ""
    for x, y, w, h in boxes:
        roi = thresh[y:y+h, x:x+w]
        size = 64
        scale = size / max(w, h)
        resized = cv2.resize(roi, (int(w * scale), int(h * scale)))
        square = np.zeros((size, size), dtype=np.uint8)
        x_offset = (size - resized.shape[1]) // 2
        y_offset = (size - resized.shape[0]) // 2
        square[y_offset:y_offset+resized.shape[0], x_offset:x_offset+resized.shape[1]] = resized

        img_array = img_to_array(square).reshape(1, 64, 64, 1) / 255.0
        pred = model.predict(img_array, verbose=0)[0]
        label_idx = np.argmax(pred)

        if label_idx < len(class_names):
            predicted_text += class_names[label_idx]
        else:
            predicted_text += '?'

    print("Predicted Line:", predicted_text)
    plt.imshow(cv2.imread(img_path), cmap='gray')
    plt.title(f"Prediction: {predicted_text}")
    plt.axis('off')
    plt.show()

# STEP 6: Run
predict_line(img_file)

# ‚úÖ STEP 1: Install dependencies
!pip install easyocr pix2tex transformers matplotlib -q
!apt install tesseract-ocr -y > /dev/null

# ‚úÖ STEP 2: Upload image
from google.colab import files
uploaded = files.upload()
img_path = list(uploaded.keys())[0]

# ‚úÖ STEP 3: Bangla OCR using EasyOCR
import easyocr
reader = easyocr.Reader(['bn'], gpu=False)
bangla_results = reader.readtext(img_path, detail=0)
bangla_text = ' '.join(bangla_results)

# ‚úÖ STEP 4: Equation OCR using pix2tex
import torch
from PIL import Image
from pix2tex.cli import LatexOCR

ocr = LatexOCR()
eq_img = Image.open(img_path)
latex_result = ocr(eq_img)

# ‚úÖ STEP 5: Display outputs
from IPython.display import display, Markdown

print("üî° Bangla Text:\n", bangla_text)
print("\nüßÆ LaTeX Equation:\n", latex_result)

# Render LaTeX inside notebook
display(Markdown(f"**üìñ Rendered Equation:**  \n\n`{latex_result}`"))

!pip uninstall -y docx
!pip install python-docx

from docx import Document

doc = Document()
doc.add_heading('Bangla OCR + Math Equation Result', level=1)

doc.add_heading('üìå Bangla Text:', level=2)
doc.add_paragraph(bangla_text)

doc.add_heading('üìå LaTeX Equation:', level=2)
doc.add_paragraph(latex_result)

doc.save("ocr_result.docx")

from google.colab import files
files.download("ocr_result.docx")

# @title üîÑ LaTeX to MathJax Converter

def latex_to_mathjax_inline(latex_str):
    return f"\\({latex_str}\\)"  # Inline math

def latex_to_mathjax_block(latex_str):
    return f"$$ {latex_str} $$"  # Block-level math

def sanitize_latex(latex_str):
    import re
    latex_str = re.sub(r'\\displaystyle', '', latex_str)
    return latex_str.strip()

latex = r"9x + 27 = 49 + x - 2 + 14\sqrt{x - 2}"

cleaned = sanitize_latex(latex)
inline_mj = latex_to_mathjax_inline(cleaned)
block_mj = latex_to_mathjax_block(cleaned)

print("Inline MathJax:\n", inline_mj)
print("Block MathJax:\n", block_mj)

html_template = f"""
<!DOCTYPE html>
<html>
<head>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
</head>
<body>
  <h3>Rendered Math (Block):</h3>
  <p>{block_mj}</p>
  <hr>
  <h3>Rendered Math (Inline):</h3>
  <p>This is inline math: {inline_mj}</p>
</body>
</html>
"""

# Save to file
with open("mathjax_preview.html", "w") as f:
    f.write(html_template)

# Download link
from google.colab import files
files.download("mathjax_preview.html")