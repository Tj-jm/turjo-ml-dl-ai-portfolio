{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style=\"border: 2px solid #2c3e50; \n",
        "            padding: 15px; \n",
        "            border-radius: 8px; \n",
        "            background-color: #e8f8f5; \n",
        "            color: #2c3e50; \n",
        "            font-family: 'Segoe UI', Tahoma, sans-serif; \n",
        "            box-shadow: 2px 2px 6px rgba(0,0,0,0.1);\">\n",
        "\n",
        "<h3 style=\"color:#117864;\">Notebook Intro</h3>\n",
        "\n",
        "<p>\n",
        "This notebook introduces fundamental NLP preprocessing and representation techniques, including tokenization, \n",
        "stopword removal, TF-IDF, and Word2Vec embeddings. As part of the series,\n",
        " it provides the essential building blocks for understanding how text data is processed and represented in machine learning models.\n",
        "\n",
        "</div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSqY45Zc2KRN",
        "outputId": "9558a5ca-7f61-40a2-9705-7f622eeb3c52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Photosynthesis', 'occurs', 'in', 'plants', '.']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(\"Photosynthesis occurs in plants.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqLvNhLO2jRN",
        "outputId": "53a16350-13de-4dde-9b5d-bbbdb71d9b6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original tokens: ['Photosynthesis', 'occurs', 'in', 'plants', '.']\n",
            "Filtered tokens: ['Photosynthesis', 'occurs', 'plants', '.']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Tokenize the sentence\n",
        "tokens = word_tokenize(\"Photosynthesis occurs in plants.\")\n",
        "\n",
        "# Download stop words if not already downloaded\n",
        "try:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "except LookupError:\n",
        "    import nltk\n",
        "    nltk.download('stopwords')\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Filter out stop words\n",
        "filtered_tokens = [w for w in tokens if w.lower() not in stop_words]\n",
        "\n",
        "print(\"Original tokens:\", tokens)\n",
        "print(\"Filtered tokens:\", filtered_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kysvPcP35tZ",
        "outputId": "0c260b15-e4d5-4469-d521-8a04b246ecd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['and' 'are' 'chemistry' 'interesting' 'is' 'physics' 'sciences']\n",
            "[[0.         0.         0.         0.6316672  0.6316672  0.44943642\n",
            "  0.        ]\n",
            " [0.47107781 0.47107781 0.47107781 0.         0.         0.33517574\n",
            "  0.47107781]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "docs = [\n",
        "    \"Physics is interesting\",\n",
        "    \"Physics and chemistry are sciences\"\n",
        "]\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(tfidf_matrix.toarray())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLPOJODN6Al5"
      },
      "source": [
        "| Representation   | Values         | Purpose    |\n",
        "| ---------------- | -------------- | ---------- |\n",
        "| One-Hot Encoding | Binary (0/1)   | Presence   |\n",
        "| Bag of Words     | Integer counts | Frequency  |\n",
        "| TF-IDF           | Decimal        | Importance |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkYtvtvlqEi8",
        "outputId": "b286e36c-7711-4ed5-e341-43352557725c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFJQTcOiqmj8",
        "outputId": "e3500943-c1ab-4951-ae54-75c99d5b901c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['the', 'cat', 'sits', 'on', 'the', 'mat'], ['the', 'dog', 'sits', 'on', 'the', 'rug'], ['cats', 'and', 'dogs', 'are', 'pets'], ['pets', 'are', 'cute', 'and', 'lovely'], ['students', 'learn', 'physics', 'and', 'chemistry']]\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    \"The cat sits on the mat\",\n",
        "    \"The dog sits on the rug\",\n",
        "    \"Cats and dogs are pets\",\n",
        "    \"Pets are cute and lovely\",\n",
        "    \"Students learn physics and chemistry\"\n",
        "]\n",
        "\n",
        "# Tokenize\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "print(tokenized_sentences)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKOroSxzrn_7"
      },
      "source": [
        "| Parameter     | Meaning                                                |\n",
        "| ------------- | ------------------------------------------------------ |\n",
        "| `vector_size` | Embedding dimension for each word                      |\n",
        "| `window`      | How many surrounding words to consider during training |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hl97rLvYq9Fq"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(\n",
        "    sentences=tokenized_sentences,\n",
        "    vector_size=50,      # embedding dimension\n",
        "    window=2,            # context window size\n",
        "    min_count=1,         # minimum word frequency to include\n",
        "    sg=1,                # 1 = skip-gram\n",
        "    epochs=100           # more epochs for small data\n",
        ")\n",
        "\n",
        "# Save if needed\n",
        "model.save(\"skipgram_demo.model\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsRkM-kWq_d4",
        "outputId": "51a3ece2-2d3b-436f-b069-b89934259b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding for 'cat':\n",
            "[-0.01923801  0.01787224  0.00830869  0.01846109  0.01324344  0.00586571\n",
            "  0.01966685 -0.00883491 -0.01377315  0.00848266  0.00749095 -0.01138246\n",
            "  0.01945744 -0.00711169  0.01909935  0.0017056  -0.01264617 -0.00376472\n",
            " -0.01492901 -0.00611466  0.00212158  0.01901883  0.01884231 -0.01324384\n",
            "  0.00697738  0.00456381 -0.0048769  -0.01838992  0.00192122 -0.01634843\n",
            "  0.01265703 -0.0116715   0.01103789  0.01960382 -0.00038975  0.00899734\n",
            " -0.00353411  0.01473381  0.00790537 -0.01802165 -0.00478091  0.00724488\n",
            " -0.00028623 -0.00237024 -0.00192607 -0.00326875  0.00116864  0.00823352\n",
            " -0.00843931 -0.00768588]\n"
          ]
        }
      ],
      "source": [
        "print(\"Embedding for 'cat':\")\n",
        "print(model.wv['cat'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1Kzp8BorEL9",
        "outputId": "771f812a-0d07-4f60-da96-78166eaeac45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Words similar to 'cat':\n",
            "[('and', 0.23322492837905884), ('physics', 0.22817462682724), ('on', 0.1325155645608902), ('pets', 0.10684175044298172), ('mat', 0.09860452264547348), ('the', 0.06264279037714005), ('chemistry', 0.05703628063201904), ('dogs', 0.05243419110774994), ('learn', -0.0052363998256623745), ('cats', -0.03842007741332054)]\n"
          ]
        }
      ],
      "source": [
        "print(\"Words similar to 'cat':\")\n",
        "print(model.wv.most_similar('cat'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7_8OFOsrGxK",
        "outputId": "6ef30750-f389-4abc-fdf1-f60c6bc7cb99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Similarity between 'cat' and 'dog': -0.08932257443666458\n"
          ]
        }
      ],
      "source": [
        "similarity = model.wv.similarity('cat', 'dog')\n",
        "print(f\"Similarity between 'cat' and 'dog': {similarity}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jsth-ydLtgwV"
      },
      "source": [
        "# Skip-gram Vector Arithmetic - Algorithm\n",
        "\n",
        "## Purpose\n",
        "Perform semantic relationship queries using trained word embeddings from a Skip-gram (Word2Vec) model.\n",
        "\n",
        "---\n",
        "\n",
        "## Inputs\n",
        "\n",
        "- Trained `Word2Vec` Skip-gram model.\n",
        "- Word A (embedding A).\n",
        "- Word B (embedding B).\n",
        "- Word C (embedding C).\n",
        "- `topn` (number of top similar words to retrieve).\n",
        "\n",
        "---\n",
        "\n",
        "## Intuition\n",
        "\n",
        "- Word embeddings capture semantic relationships as directions in vector space.\n",
        "- \"king\" - \"man\" removes the male component, retaining royalty.\n",
        "- Adding \"woman\" adds the female component.\n",
        "- Resulting vector points towards \"queen\".\n",
        "\n",
        "---\n",
        "\n",
        "## Steps\n",
        "\n",
        "1. Retrieve embeddings:\n",
        "    - `vec_A = embedding(\"A\")`\n",
        "    - `vec_B = embedding(\"B\")`\n",
        "    - `vec_C = embedding(\"C\")`\n",
        "\n",
        "2. Compute the arithmetic:\n",
        "$$ \\text{result\\_vector} = \\text{vec\\_A} - \\text{vec\\_B} + \\text{vec\\_C} $$\n",
        "\n",
        "3. For each word `w` in the vocabulary:\n",
        "    - Compute:\n",
        "$$ \\text{cosine\\_similarity}(\\text{result\\_vector}, \\text{embedding}(w))\n",
        "        $$\n",
        "\n",
        "4. Sort the words by cosine similarity in descending order.\n",
        "\n",
        "5. Return the top `topn` words with highest similarity as **predicted related words**.\n",
        "\n",
        "---\n",
        "\n",
        "## Code Snippet (Gensim)\n",
        "\n",
        "```python\n",
        "result = model.wv.most_similar(\n",
        "    positive=[word_a, word_c],\n",
        "    negative=[word_b],\n",
        "    topn=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AIheq22rKVd",
        "outputId": "fad1596a-5f8e-48ac-eb3d-97c21e50361b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('and', 0.3115268647670746), ('on', 0.12320028245449066), ('the', 0.09282376617193222), ('mat', 0.023975085467100143), ('pets', -0.014839722774922848), ('cats', -0.0207061804831028), ('chemistry', -0.021130019798874855), ('cute', -0.021545285359025), ('dogs', -0.08284758031368256), ('learn', -0.0889245793223381)]\n"
          ]
        }
      ],
      "source": [
        "result = model.wv.most_similar(positive=['dog', 'cat'], negative=['physics'])\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
